---
layout: post
title: Sam图像分割模型
tags:
- Sam
categories: 图像分割
description: SAM（Segment Anything Model）是Meta AI于2023年推出的通用图像分割模型，通过大规模训练（1100万张图像+11亿掩码）实现零样本分割，支持点、框、文本等交互提示，无需微调即可分割任意对象。其核心基于ViT编码器、提示编码器和掩码解码器，兼具强泛化能力和多场景适用性（如医疗、遥感），但复杂边缘处理和高算力需求仍是挑战。✨
---

### 模型介绍

> SAM（Segment Anything Model）是Meta AI于2023年推出的通用图像分割模型，通过大规模训练（1100万张图像+11亿掩码）实现零样本分割，支持点、框、文本等交互提示，无需微调即可分割任意对象。其核心基于ViT编码器、提示编码器和掩码解码器，兼具强泛化能力和多场景适用性（如医疗、遥感），但复杂边缘处理和高算力需求仍是挑战。

---

### 安装部署

```
git clone git@github.com:facebookresearch/segment-anything.git
cd segment-anything; pip install -e .   
pip install opencv-python pycocotools matplotlib onnxruntime onnx
```

安装完毕后，可选择下载 vit_b模型权重文件: [ViT-B SAM model.](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth)

---

### 图像分割示例
```
python scripts/amg.py
--checkpoint /Users/pengzhang/segment-anything/model/sam_vit_b_01ec64.pth
--model-type vit_b
--input /Users/pengzhang/segment-anything/input_imgs
--output /Users/pengzhang/segment-anything/output_imgs
--device cpu
```
Sam模型工程目录下的scripts/amg.py文件详解了命令参数
--checkpoint：权重文件路径    
--model-type：模型类型，参考[Model Checkpoints](https://github.com/facebookresearch/segment-anything?tab=readme-ov-file#model-checkpoints)     
--input：输入图片文件夹    
--output：输出图片文件夹
--device：由于部署机器是macbook air，因此选择cpu   

![](https://raw.githubusercontent.com/QuantPengPeng/quantpengpeng.github.io/refs/heads/master/_data/post_img/2025-05-07-sam/sam_dir.png){width=200px,height=500px}   


---

### 参考文献
[segment-anything](https://github.com/facebookresearch/segment-anything?tab=readme-ov-file#model-checkpoints)   
[Segment Anything Model (SAM)本地部署，及应用于自己的数据集完成分割](https://blog.csdn.net/MayYou_SSS/article/details/132719786)    